<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="The Sound of Simulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    The Sound of Simulation
  </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
            The Sound of Simulation: Learning Multimodal Sim-to-Real Robot Policies with Generative Audio
          </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"> 
                <a href="https://renwang435.github.io/">Renhao Wang</a>,
              </span>
              <span class="author-block"> 
                <a href="https://geng-haoran.github.io/">Haoran Geng</a>,
              </span>
              <span class="author-block"> 
                <a href="https://tinglok.netlify.app/">Tingle Li</a>,
              </span>
              <span class="author-block"> 
                <a href="https://scholar.google.com/citations?user=eGG8hJgAAAAJ&hl=en">Feishi Wang</a>,
              </span>
              <span class="author-block"> 
                <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/gopala.html">Gopala Anumanchipalli</a>,
              </span>
              <br>
              <span class="author-block"> 
                <a href="https://sites.google.com/site/boyilics/home">Boyi Li</a>,
              </span>
              <span class="author-block"> 
                <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>,
              </span>
              <span class="author-block"> 
                <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>,
              </span>
              <span class="author-block"> 
                <a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a>,
              </span>
              <span class="author-block"> 
                <a href="https://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>
              </span>
              <br>
              <span class="authors-affiliation">UC Berkeley</span>
              <br>
              <!-- <br> -->
              <div class="is-size-6 publication-authors">
                <!-- <span style="font-size: 0.9em;">*Equal Contribution</span><br> -->
                <span class="author-block">Conference on Robot Learning (CoRL) 2025 <i><span class="achievement_finalist">[Best Paper Finalist]</span></i></span>
              </div>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2507.02864" target="_blank" 
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- <span class="link-block"> <a href="https://www.youtube.com/watch?v=z6BsJYY-5UU" target="_blank"
                                             class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <span class="link-block"> 
                  <a href="https://github.com/renwang435/multigen" target="_blank" 
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fa fa-book"></i>
                    </span>
                    <span>PowerPoint</span>
                    </a>
                </span>
                <span class="link-block"> 
                  <a href="bibtex.txt" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <!-- <span class="icon">
                      <i class="fab fa-github"></i>
                    </span> -->
                    <span>BibTeX</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/z6BsJYY-5UU?rel=0&amp;showinfo=0" frameborder="0"
                    allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div> -->
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <p style="text-align:center;">
      <img width="100%" src="images/teaser.png">
    </p>
    <p style="font-size: 18px; text-align: center">
      Lorem ipsum
    </p>
  </div>
</section> -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <p style="text-align:center;">
      <img width="100%" src="images/teaser.png">
    </p>
    <!-- <p style="font-size: 18px; text-align: center">
      Lorem ipsum
    </p> -->
    <!-- <div class="columns is-centered">
      <video controls muted loop autoplay playsinline height="100%" width="100%">
        <source src="videos/teaser.mp4" type="video/mp4"/>
      </video>
    </div> -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robots must integrate multiple sensory modalities to act effectively in the real world. 
            Yet, learning such multimodal policies at scale remains challenging. Simulation offers a viable solution, 
            but while vision has benefited from high-fidelity simulators, other modalities (e.g. sound) remain
            difficult to simulate. As a result, sim-to-real transfer has succeeded primarily in vision-based tasks,
            with multimodal transfer largely unrealized. To address these challenges, we propose MULTIGEN: a framework that integrates 
            large-scale generative models into traditional physics simulators, enabling multisensory simulation. We showcase 
            our framework on the dynamic task of robot pouring, which inherently relies on multimodal feedback. By synthesizing 
            realistic audio conditioned on simulation video, our method enables training on rich audiovisual trajectoriesâ€”without any 
            real robot data. We demonstrate effective zero-shot transfer to real-world pouring with novel containers and liquids, 
            highlighting the potential of generative modeling to both simulate hard-to-model modalities and close the multimodal 
            sim-to-real gap.
          </p>
          <br>
          <br>
        </div>

        <h2 class="title is-2">Zero-Shot Generalization from Sim-to-Real</h2>
        <br>

        <div class="content has-text-justified">
          <p>
          Our multimodal policies, trained only on simulated audiovisual and proprioceptive data,
          exhibit strong zero-shot generalization to a variety of real-world pouring tasks. This includes novel containers,
          novel liquids, and different environmental conditions.
          </p>
          <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
            <div class="column has-text-centered">
              <video autoplay muted loop playsinline width="100%">
                <source src="videos/thermos_mug.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
        </div>

        <div class="content has-text-justified">
            <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
              <div class="column has-text-centered">
                <video autoplay muted loop playsinline width="100%">
                  <source src="videos/sake_carafe.mp4" type="video/mp4"/>
                </video>
              </div>
            </div>
        </div>

        <div class="content has-text-justified">
          <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
            <div class="column has-text-centered">
                  <video autoplay muted loop playsinline width="100%">
                      <source src="videos/orange_juice.mp4" type="video/mp4"/>
                  </video>
            </div>
          </div>
        </div>

        <div class="content has-text-justified">
          <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
            <div class="column has-text-centered">
              <video autoplay muted loop playsinline width="100%">
                <source src="videos/coke.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
        </div>

        <!-- <br>
        <br> -->


        <h2 class="title is-2">Robustness to Environmental Variations</h2>
        <div class="content has-text-justified">
            <p>
                Our multimodal policies demonstrate robustness to various environmental changes, such as different 
                background noises and lighting conditions. This robustness stems from the rich sensory feedback 
                provided by the audio modality, which helps the policy adapt to changes that may not be visually apparent.
            </p>
            <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
                <div class="column has-text-centered">
                    <figure>
                        <video autoplay muted loop playsinline width="100%">
                            <source src="videos/robustness_vision_only.mp4" type="video/mp4"/>
                        </video>
                        <figcaption><b>Vision-Only Policy</b></figcaption>
                    </figure>
                </div>
                <div class="column has-text-centered">
                    <figure>
                        <video autoplay muted loop playsinline width="100%">
                            <source src="videos/robustness_audio_vision.mp4" type="video/mp4"/>
                        </video>
                        <figcaption><b>Audio + Vision Policy </b></figcaption>
                    </figure>
                </div>
            </div>
        </div>
      <br>
      <br>



<!-- End of content -->
      <br/>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <div class="columns is-centered"><p>
            This website template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          </p></div>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
